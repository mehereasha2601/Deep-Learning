{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1n3hGSNX7NX"
      },
      "source": [
        "# Programming assignment 2: Convolutional Neural Networks (100 points)\n",
        "\n",
        "## Overview\n",
        "<font size='4'> In this assignment you will practice putting together a Convolution Neural Network (CNN) classification pipeline. So far we have worked with deep fully-connected networks, using them to explore different optimization strategies and network architectures. Fully-connected networks are a good testbed for experimentation because they are computationally efficient, but in practice CNNs work better for image classification.\n",
        "\n",
        "<font size='4'>In the first part , you will implement several layer types that are used in convolutional networks using Numpy. In the second part, you will then implement a custom CNN and ones based on the ResNet using PyTorch. You will also practice hyper parameter tuning to achieve desired accuracy.\n",
        "\n",
        "## Submission format\n",
        "* <font size='4'>`<your_nu_username>_pa2.ipynb`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-bQYoL5X7NY"
      },
      "source": [
        "## setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DnjiPjyrX7NZ"
      },
      "outputs": [],
      "source": [
        "# As usual, a bit of setup\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "# for auto-reloading external modules\n",
        "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "def rel_error(x, y):\n",
        "    \"\"\" returns relative error \"\"\"\n",
        "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6mdfI_ypX7Na"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/sh: wget: command not found\n",
            "tar: Error opening archive: Failed to open 'cifar-10-python.tar.gz'\n",
            "rm: cifar-10-python.tar.gz: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# let's download the data\n",
        "# !mkdir ../datasets\n",
        "# !cd ../datasets\n",
        "\n",
        "# 1 -- Linux\n",
        "# 2 -- MacOS\n",
        "# 3 -- Command Prompt on Windows\n",
        "# 4 -- manually downloading the data\n",
        "choice = 1\n",
        "\n",
        "\n",
        "if choice == 1:\n",
        "    # should work well on Linux and in Powershell on Windows\n",
        "    !wget http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
        "elif choice == 2 or choice ==3:\n",
        "    # if wget is not available for you, try curl\n",
        "    # should work well on MacOS\n",
        "    !curl http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz --output cifar-10-python.tar.gz\n",
        "else:\n",
        "    print('Please manually download the data from http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz and put it under the datasets folder.')\n",
        "!tar -xzvf cifar-10-python.tar.gz\n",
        "\n",
        "if choice==3:\n",
        "    !del cifar-10-python.tar.gz\n",
        "else:\n",
        "    !rm cifar-10-python.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XnslsToKX7Na"
      },
      "outputs": [],
      "source": [
        "# helpful functions to process and load the data\n",
        "from six.moves import cPickle as pickle\n",
        "import numpy as np\n",
        "import os\n",
        "from imageio import imread\n",
        "import platform\n",
        "\n",
        "def load_pickle(f):\n",
        "    version = platform.python_version_tuple()\n",
        "    if version[0] == '2':\n",
        "        return  pickle.load(f)\n",
        "    elif version[0] == '3':\n",
        "        return  pickle.load(f, encoding='latin1')\n",
        "    raise ValueError(\"invalid python version: {}\".format(version))\n",
        "\n",
        "def load_CIFAR_batch(filename):\n",
        "  \"\"\" load single batch of cifar \"\"\"\n",
        "  with open(filename, 'rb') as f:\n",
        "    datadict = load_pickle(f)\n",
        "    X = datadict['data']\n",
        "    Y = datadict['labels']\n",
        "    X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n",
        "    Y = np.array(Y)\n",
        "    return X, Y\n",
        "\n",
        "def load_CIFAR10(ROOT):\n",
        "  \"\"\" load all of cifar \"\"\"\n",
        "  xs = []\n",
        "  ys = []\n",
        "  for b in range(1,6):\n",
        "    f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n",
        "    X, Y = load_CIFAR_batch(f)\n",
        "    xs.append(X)\n",
        "    ys.append(Y)\n",
        "  Xtr = np.concatenate(xs)\n",
        "  Ytr = np.concatenate(ys)\n",
        "  del X, Y\n",
        "  Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
        "  return Xtr, Ytr, Xte, Yte\n",
        "\n",
        "\n",
        "def get_CIFAR10_data(cifar10_dir, num_training=49000, num_validation=1000, num_test=1000,\n",
        "                     subtract_mean=True):\n",
        "    \"\"\"\n",
        "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
        "    it for classifiers. These are the same steps as we used for the SVM, but\n",
        "    condensed to a single function.\n",
        "    \"\"\"\n",
        "    # Load the raw CIFAR-10 data\n",
        "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
        "\n",
        "    # Subsample the data\n",
        "    mask = list(range(num_training, num_training + num_validation))\n",
        "    X_val = X_train[mask]\n",
        "    y_val = y_train[mask]\n",
        "    mask = list(range(num_training))\n",
        "    X_train = X_train[mask]\n",
        "    y_train = y_train[mask]\n",
        "    mask = list(range(num_test))\n",
        "    X_test = X_test[mask]\n",
        "    y_test = y_test[mask]\n",
        "\n",
        "    # Normalize the data: subtract the mean image\n",
        "    if subtract_mean:\n",
        "      mean_image = np.mean(X_train, axis=0)\n",
        "      X_train -= mean_image\n",
        "      X_val -= mean_image\n",
        "      X_test -= mean_image\n",
        "\n",
        "    # Transpose so that channels come first\n",
        "    X_train = X_train.transpose(0, 3, 1, 2).copy()\n",
        "    X_val = X_val.transpose(0, 3, 1, 2).copy()\n",
        "    X_test = X_test.transpose(0, 3, 1, 2).copy()\n",
        "\n",
        "    # Package data into a dictionary\n",
        "    return {\n",
        "      'X_train': X_train, 'y_train': y_train,\n",
        "      'X_val': X_val, 'y_val': y_val,\n",
        "      'X_test': X_test, 'y_test': y_test,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iw9bYKMefeRK"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './cifar-10-batches-py/data_batch_1'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the (preprocessed) CIFAR10 data.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m cifar10_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./cifar-10-batches-py\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mget_CIFAR10_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcifar10_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubtract_mean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m pix_mean \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0.485\u001b[39m, \u001b[38;5;241m0.456\u001b[39m, \u001b[38;5;241m0.406\u001b[39m)\n\u001b[1;32m      7\u001b[0m pix_std \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m)\n",
            "Cell \u001b[0;32mIn[3], line 50\u001b[0m, in \u001b[0;36mget_CIFAR10_data\u001b[0;34m(cifar10_dir, num_training, num_validation, num_test, subtract_mean)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03mLoad the CIFAR-10 dataset from disk and perform preprocessing to prepare\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03mit for classifiers. These are the same steps as we used for the SVM, but\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03mcondensed to a single function.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Load the raw CIFAR-10 data\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m X_train, y_train, X_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mload_CIFAR10\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcifar10_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Subsample the data\u001b[39;00m\n\u001b[1;32m     53\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(num_training, num_training \u001b[38;5;241m+\u001b[39m num_validation))\n",
            "Cell \u001b[0;32mIn[3], line 32\u001b[0m, in \u001b[0;36mload_CIFAR10\u001b[0;34m(ROOT)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m6\u001b[39m):\n\u001b[1;32m     31\u001b[0m   f \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ROOT, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_batch_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (b, ))\n\u001b[0;32m---> 32\u001b[0m   X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mload_CIFAR_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m   xs\u001b[38;5;241m.\u001b[39mappend(X)\n\u001b[1;32m     34\u001b[0m   ys\u001b[38;5;241m.\u001b[39mappend(Y)\n",
            "Cell \u001b[0;32mIn[3], line 18\u001b[0m, in \u001b[0;36mload_CIFAR_batch\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_CIFAR_batch\u001b[39m(filename):\n\u001b[1;32m     17\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\" load single batch of cifar \"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     19\u001b[0m     datadict \u001b[38;5;241m=\u001b[39m load_pickle(f)\n\u001b[1;32m     20\u001b[0m     X \u001b[38;5;241m=\u001b[39m datadict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/argoverse/lib/python3.9/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './cifar-10-batches-py/data_batch_1'"
          ]
        }
      ],
      "source": [
        "# Load the (preprocessed) CIFAR10 data.\n",
        "cifar10_dir = './cifar-10-batches-py'\n",
        "\n",
        "data = get_CIFAR10_data(cifar10_dir, subtract_mean=True)\n",
        "\n",
        "pix_mean = (0.485, 0.456, 0.406)\n",
        "pix_std = (0.229, 0.224, 0.225)\n",
        "\n",
        "for c in range(3):\n",
        "    data['X_train'][:, c] = (data['X_train'][:, c] / 255 - pix_mean[c]) / pix_std[c]\n",
        "    data['X_val'][:, c] = (data['X_val'][:, c] / 255 - pix_mean[c]) / pix_std[c]\n",
        "    data['X_test'][:, c] = (data['X_test'][:, c] / 255 - pix_mean[c]) / pix_std[c]\n",
        "\n",
        "for split in ['train', 'val', 'test']:\n",
        "    print('===\\nFor the split {}'.format(split))\n",
        "    print('shape: {}'.format(data['X_{}'.format(split)].shape))\n",
        "    print('data value range, min: {}, max: {}\\n'.format(data['X_{}'.format(split)].min(), data['X_{}'.format(split)].max()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMLkz8Y2X7Na"
      },
      "source": [
        "## Part 1: Implementing convolution and batch normalization layers using Numpy (25 points)\n",
        "(adapted from the work done by Erik Learned-Miller, which was originally developed by Fei-Fei Li, Andrej Karpathy, and Justin Johnson)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2Cz4RqdX7Na"
      },
      "source": [
        "<font size=\"4\" color=\"red\">**task 1.1: forward pass of a convolution layer with two nested for loops (10 points)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dq9kNQomX7Na"
      },
      "outputs": [],
      "source": [
        "def conv_forward_naive(x, w, b, conv_param):\n",
        "    \"\"\"\n",
        "    A naive implementation of the forward pass for a convolutional layer.\n",
        "\n",
        "    The input consists of N data points, each with C channels, height H and\n",
        "    width W. We convolve each input with F different filters, where each filter\n",
        "    spans all C channels and has height HH and width WW.\n",
        "\n",
        "    Input:\n",
        "    - x: Input data of shape (N, C, H, W)\n",
        "    - w: Filter weights of shape (F, C, HH, WW)\n",
        "    - b: Biases, of shape (F,)\n",
        "    - conv_param: A dictionary with the following keys:\n",
        "      - 'stride': The number of pixels between adjacent receptive fields in the\n",
        "        horizontal and vertical directions.\n",
        "      - 'pad': The number of pixels that will be used to zero-pad the input.\n",
        "\n",
        "\n",
        "    During padding, 'pad' zeros should be placed symmetrically (i.e equally on both sides)\n",
        "    along the height and width axes of the input. Be careful not to modfiy the original\n",
        "    input x directly.\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - out: Output data, of shape (N, F, H', W') where H' and W' are given by\n",
        "      H' = ceil((H + 2 * pad - HH + 1) / stride)\n",
        "      W' = ceil((W + 2 * pad - WW + 1) / stride)\n",
        "    - cache: (x, w, b, conv_param)\n",
        "    \"\"\"\n",
        "    out = None\n",
        "\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the convolutional forward pass.                         #\n",
        "    # Hint: you can use the function np.pad for padding.                      #\n",
        "    ###########################################################################\n",
        "    raise NotImplementedError\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "\n",
        "    cache = (x, w, b, conv_param)\n",
        "    return out, cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-xIe8azX7Na"
      },
      "outputs": [],
      "source": [
        "# check your forward pass implementation\n",
        "x_shape = (2, 3, 4, 4)\n",
        "w_shape = (3, 3, 4, 4)\n",
        "x = np.linspace(-0.1, 0.5, num=np.prod(x_shape)).reshape(x_shape)\n",
        "w = np.linspace(-0.2, 0.3, num=np.prod(w_shape)).reshape(w_shape)\n",
        "b = np.linspace(-0.1, 0.2, num=3)\n",
        "\n",
        "conv_param = {'stride': 2, 'pad': 1}\n",
        "out, _ = conv_forward_naive(x, w, b, conv_param)\n",
        "correct_out = np.array([[[[-0.08759809, -0.10987781],\n",
        "                           [-0.18387192, -0.2109216 ]],\n",
        "                          [[ 0.21027089,  0.21661097],\n",
        "                           [ 0.22847626,  0.23004637]],\n",
        "                          [[ 0.50813986,  0.54309974],\n",
        "                           [ 0.64082444,  0.67101435]]],\n",
        "                         [[[-0.98053589, -1.03143541],\n",
        "                           [-1.19128892, -1.24695841]],\n",
        "                          [[ 0.69108355,  0.66880383],\n",
        "                           [ 0.59480972,  0.56776003]],\n",
        "                          [[ 2.36270298,  2.36904306],\n",
        "                           [ 2.38090835,  2.38247847]]]])\n",
        "\n",
        "# Compare your output to ours; difference should be around e-8\n",
        "print('Testing conv_forward_naive')\n",
        "print('difference: ', rel_error(out, correct_out))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOOLqcs1X7Nb"
      },
      "source": [
        "<font size='4' color='red'>**Task 1.2: forward pass of a (normal) batch norm layer (10 points).**\n",
        "\n",
        "<font size='4'>Batch normalization is a very useful technique for training deep neural networks. As proposed in the original paper [1], batch normalization can also be used for convolutional networks, but we need to tweak it a bit; the modification will be called \"spatial batch normalization.\"\n",
        "\n",
        "<font size='4'>Normally batch-normalization accepts inputs of shape `(N, D)` and produces outputs of shape `(N, D)`, where we normalize across the minibatch dimension `N`.\n",
        "\n",
        "[1] [Sergey Ioffe and Christian Szegedy, \"Batch Normalization: Accelerating Deep Network Training by Reducing\n",
        "Internal Covariate Shift\", ICML 2015.](https://arxiv.org/abs/1502.03167)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XT_sIvjPX7Nb"
      },
      "outputs": [],
      "source": [
        "def batchnorm_forward(x, gamma, beta, bn_param):\n",
        "    \"\"\"\n",
        "    Forward pass for batch normalization.\n",
        "\n",
        "    During training the sample mean and (uncorrected) sample variance are\n",
        "    computed from minibatch statistics and used to normalize the incoming data.\n",
        "    During training we also keep an exponentially decaying running mean of the\n",
        "    mean and variance of each feature, and these averages are used to normalize\n",
        "    data at test-time.\n",
        "\n",
        "    At each timestep we update the running averages for mean and variance using\n",
        "    an exponential decay based on the momentum parameter:\n",
        "\n",
        "    running_mean = momentum * running_mean + (1 - momentum) * sample_mean\n",
        "    running_var = momentum * running_var + (1 - momentum) * sample_var\n",
        "\n",
        "    Note that the batch normalization paper suggests a different test-time\n",
        "    behavior: they compute sample mean and variance for each feature using a\n",
        "    large number of training images rather than using a running average. For\n",
        "    this implementation we have chosen to use running averages instead since\n",
        "    they do not require an additional estimation step; the PyTorch\n",
        "    implementation of batch normalization also uses running averages.\n",
        "\n",
        "    Input:\n",
        "    - x: Data of shape (N, D)\n",
        "    - gamma: Scale parameter of shape (D,)\n",
        "    - beta: Shift paremeter of shape (D,)\n",
        "    - bn_param: Dictionary with the following keys:\n",
        "      - mode: 'train' or 'test'; required\n",
        "      - eps: Constant for numeric stability\n",
        "      - momentum: Constant for running mean / variance.\n",
        "      - running_mean: Array of shape (D,) giving running mean of features\n",
        "      - running_var Array of shape (D,) giving running variance of features\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - out: of shape (N, D)\n",
        "    - cache: A tuple of values needed in the backward pass\n",
        "    \"\"\"\n",
        "    mode = bn_param['mode']\n",
        "    eps = bn_param.get('eps', 1e-5)\n",
        "    momentum = bn_param.get('momentum', 0.9)\n",
        "\n",
        "    N, D = x.shape\n",
        "    running_mean = bn_param.get('running_mean', np.zeros(D, dtype=x.dtype))\n",
        "    running_var = bn_param.get('running_var', np.zeros(D, dtype=x.dtype))\n",
        "\n",
        "    out, cache = None, None\n",
        "    if mode == 'train':\n",
        "        #######################################################################\n",
        "        # TODO: Implement the training-time forward pass for batch norm.      #\n",
        "        # Use minibatch statistics to compute the mean and variance, use      #\n",
        "        # these statistics to normalize the incoming data, and scale and      #\n",
        "        # shift the normalized data using gamma and beta. Simply treat the    #\n",
        "        # sample mean and sample variance as constants to simplify the        #\n",
        "        # gradients computation.                                              #\n",
        "        #                                                                     #\n",
        "        # You should store the output in the variable out. Any intermediates  #\n",
        "        # that you need for the backward pass should be stored in the cache   #\n",
        "        # variable.                                                           #\n",
        "        #                                                                     #\n",
        "        # You should also use your computed sample mean and variance together #\n",
        "        # with the momentum variable to update the running mean and running   #\n",
        "        # variance, storing your result in the running_mean and running_var   #\n",
        "        # variables.                                                          #\n",
        "        #                                                                     #\n",
        "        # Note that though you should be keeping track of the running         #\n",
        "        # variance, you should normalize the data based on the standard       #\n",
        "        # deviation (square root of variance) instead!                        #\n",
        "        # Referencing the original paper (https://arxiv.org/abs/1502.03167)   #\n",
        "        # might prove to be helpful.                                          #\n",
        "        #######################################################################\n",
        "        raise NotImplementedError\n",
        "        #######################################################################\n",
        "        #                           END OF YOUR CODE                          #\n",
        "        #######################################################################\n",
        "    elif mode == 'test':\n",
        "        #######################################################################\n",
        "        # TODO: Implement the test-time forward pass for batch normalization. #\n",
        "        # Use the running mean and variance to normalize the incoming data,   #\n",
        "        # then scale and shift the normalized data using gamma and beta.      #\n",
        "        # Store the result in the out variable.                               #\n",
        "        #######################################################################\n",
        "        raise NotImplementedError\n",
        "        #######################################################################\n",
        "        #                          END OF YOUR CODE                           #\n",
        "        #######################################################################\n",
        "    else:\n",
        "        raise ValueError('Invalid forward batchnorm mode \"%s\"' % mode)\n",
        "\n",
        "    # Store the updated running means back into bn_param\n",
        "    bn_param['running_mean'] = running_mean\n",
        "    bn_param['running_var'] = running_var\n",
        "\n",
        "    return out, cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-YNqB7LX7Nb"
      },
      "source": [
        "<font size='4' color='red'>**Task 1.3: forward pass of a spatial batch norm layer (5 points).**\n",
        "\n",
        "<font size='4'>For data coming from convolutional layers, batch normalization needs to accept inputs of shape `(N, C, H, W)` and produce outputs of shape `(N, C, H, W)` where the `N` dimension gives the minibatch size and the `(H, W)` dimensions give the spatial size of the feature map. In specific, we expect the statistics of each feature channel to be relatively consistent both between different imagesand different locations within the same image. Therefore spatial batch normalization computes a mean and variance for each of the `C` feature channels by computing statistics over both the minibatch dimension `N` and the spatial dimensions `H` and `W`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZ0ydd_7X7Nb"
      },
      "outputs": [],
      "source": [
        "def spatial_batchnorm_forward(x, gamma, beta, bn_param):\n",
        "    \"\"\"\n",
        "    Computes the forward pass for spatial batch normalization.\n",
        "\n",
        "    Inputs:\n",
        "    - x: Input data of shape (N, C, H, W)\n",
        "    - gamma: Scale parameter, of shape (C,)\n",
        "    - beta: Shift parameter, of shape (C,)\n",
        "    - bn_param: Dictionary with the following keys:\n",
        "      - mode: 'train' or 'test'; required\n",
        "      - eps: Constant for numeric stability\n",
        "      - momentum: Constant for running mean / variance. momentum=0 means that\n",
        "        old information is discarded completely at every time step, while\n",
        "        momentum=1 means that new information is never incorporated. The\n",
        "        default of momentum=0.9 should work well in most situations.\n",
        "      - running_mean: Array of shape (D,) giving running mean of features\n",
        "      - running_var Array of shape (D,) giving running variance of features\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - out: Output data, of shape (N, C, H, W)\n",
        "    - cache: Values needed for the backward pass\n",
        "    \"\"\"\n",
        "    out, cache = None, None\n",
        "\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the forward pass for spatial batch normalization.       #\n",
        "    #                                                                         #\n",
        "    # HINT: You can implement spatial batch normalization by calling the      #\n",
        "    # vanilla version of batch normalization you implemented above.           #\n",
        "    # Your implementation should be very short; ours is less than five lines. #\n",
        "    ###########################################################################\n",
        "    raise NotImplementedError\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "\n",
        "    return out, cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svaOyaKGX7Nb"
      },
      "outputs": [],
      "source": [
        "np.random.seed(231)\n",
        "# Check the training-time forward pass by checking means and variances\n",
        "# of features both before and after spatial batch normalization\n",
        "\n",
        "N, C, H, W = 2, 3, 4, 5\n",
        "x = 4 * np.random.randn(N, C, H, W) + 10\n",
        "\n",
        "print('Before spatial batch normalization:')\n",
        "print('  Shape: ', x.shape)\n",
        "print('  Means: ', x.mean(axis=(0, 2, 3)))\n",
        "print('  Stds: ', x.std(axis=(0, 2, 3)))\n",
        "\n",
        "# Means should be close to zero and stds close to one\n",
        "gamma, beta = np.ones(C), np.zeros(C)\n",
        "bn_param = {'mode': 'train'}\n",
        "out, _ = spatial_batchnorm_forward(x, gamma, beta, bn_param)\n",
        "print('After spatial batch normalization:')\n",
        "print('  Shape: ', out.shape)\n",
        "print('  Means: ', out.mean(axis=(0, 2, 3)))\n",
        "print('  Stds: ', out.std(axis=(0, 2, 3)))\n",
        "\n",
        "# Means should be close to beta and stds close to gamma\n",
        "gamma, beta = np.asarray([3, 4, 5]), np.asarray([6, 7, 8])\n",
        "out, _ = spatial_batchnorm_forward(x, gamma, beta, bn_param)\n",
        "print('After spatial batch normalization (nontrivial gamma, beta):')\n",
        "print('  Shape: ', out.shape)\n",
        "print('  Means: ', out.mean(axis=(0, 2, 3)))\n",
        "print('  Stds: ', out.std(axis=(0, 2, 3)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMVSh7QPX7Nc"
      },
      "outputs": [],
      "source": [
        "np.random.seed(231)\n",
        "# Check the test-time forward pass by running the training-time\n",
        "# forward pass many times to warm up the running averages, and then\n",
        "# checking the means and variances of activations after a test-time\n",
        "# forward pass.\n",
        "N, C, H, W = 10, 4, 11, 12\n",
        "\n",
        "bn_param = {'mode': 'train'}\n",
        "gamma = np.ones(C)\n",
        "beta = np.zeros(C)\n",
        "for t in range(50):\n",
        "  x = 2.3 * np.random.randn(N, C, H, W) + 13\n",
        "  spatial_batchnorm_forward(x, gamma, beta, bn_param)\n",
        "bn_param['mode'] = 'test'\n",
        "x = 2.3 * np.random.randn(N, C, H, W) + 13\n",
        "a_norm, _ = spatial_batchnorm_forward(x, gamma, beta, bn_param)\n",
        "\n",
        "# Means should be close to zero and stds close to one, but will be\n",
        "# noisier than training-time forward passes.\n",
        "print('After spatial batch normalization (test-time):')\n",
        "print('  means: ', a_norm.mean(axis=(0, 2, 3)))\n",
        "print('  stds: ', a_norm.std(axis=(0, 2, 3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMs1zpyjX7Nd"
      },
      "source": [
        "## Part 2: Implementing CNNs (Convolutional Neural Networks) using PyTorch (75 points)\n",
        "<font size='4'>You may find the documentation of PyTorch useful https://pytorch.org/docs/stable/index.html."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5lX9yRwX7Nd"
      },
      "source": [
        "<font size='4' color='red'>**Task 2.1: Implement a custom CNN (12 points).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjD5dpkwZZkI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    \"\"\"\n",
        "    A simple convolutional network with the following architecture:\n",
        "\n",
        "    [conv - bn - relu] x M - global_average_pooling - affine - softmax\n",
        "\n",
        "    \"[conv - bn - relu] x M\" means the \"conv-bn-relu\" block is repeated for\n",
        "    M times, where M is implicitly defined by the convolution layers' parameters.\n",
        "    Whether to use the batch normalization layer (bn) in-between is a design choice.\n",
        "\n",
        "    For each convolution layer, we do downsampling of factor 2 by setting the stride\n",
        "    to be 2. So we can have a large receptive field size.\n",
        "\n",
        "    The network operates on minibatches of data that have shape (N, C, H, W)\n",
        "    consisting of N images, each with height H and width W and with C input\n",
        "    channels.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim=(3, 32, 32), filter_sizes=[7], filter_channels=[32],\n",
        "            num_classes=10, use_batch_norm=True):\n",
        "        \"\"\"\n",
        "        Initialize a new CNN.\n",
        "\n",
        "        Inputs:\n",
        "        - input_dim: Tuple (C, H, W) giving size of input data\n",
        "        - filter_sizes: Width/height of filters to use in the convolutional layer. It is a\n",
        "          list whose length defines the number of convolution layers.\n",
        "        - filter_channels: Number of filters to use in each convolutional layer. It has the\n",
        "          same length as filter_sizes.\n",
        "        - num_classes: Number of output classes\n",
        "        - use_batch_norm: A boolean variable indicating whether to use batch normalization\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        assert len(filter_sizes) == len(filter_channels), \"Inconsistent filter sizes and channels.\"\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Define a set of layers according to the user input.                #\n",
        "        #                                                                          #\n",
        "        # IMPORTANT:                                                               #\n",
        "        # 1. For this assignment, you can assume that the padding of the every     #\n",
        "        # convolutional layer are chosen so that **the width and height of the     #\n",
        "        # input are preserved** (without considering the stride). You need to      #\n",
        "        # carefully set the `pad` parameter for the convolution.                   #\n",
        "        #                                                                          #\n",
        "        # 2. For each convolution layer, we use stride of 2 to do downsampling.    #\n",
        "        ############################################################################\n",
        "        raise NotImplementedError\n",
        "        ############################################################################\n",
        "        #                             END OF YOUR CODE                             #\n",
        "        ############################################################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = None\n",
        "        feat_before_gap = None\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Implement the forward pass for the simple convolutional net,       #\n",
        "        # computing the class scores for x and storing them in the logits          #\n",
        "        # variable. Also, store the feature map right before the global average    #\n",
        "        # pooling (GAP) layer in the feat_before_gap variable for debugging        #\n",
        "        # purpose only.                                                            #\n",
        "        ############################################################################\n",
        "        raise NotImplementedError\n",
        "        ############################################################################\n",
        "        #                             END OF YOUR CODE                             #\n",
        "        ############################################################################\n",
        "\n",
        "        return logits, feat_before_gap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jm-k2zX_cxJd"
      },
      "outputs": [],
      "source": [
        "# Sanity check of the model\n",
        "model = ConvNet(filter_sizes=[3, 3, 3], filter_channels=[4, 8, 16])\n",
        "print(model)\n",
        "\n",
        "x = torch.rand((4, 3, 32, 32))\n",
        "logits, feat_before_gap = model(x)\n",
        "assert logits.shape == torch.Size([4, 10]), \"Incorrect shape for the logits\"\n",
        "print(feat_before_gap.shape)\n",
        "assert feat_before_gap.shape == torch.Size([4, 16, 4, 4]), \"Incorrect shape for the feature map before the GAP layer\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIg6XrIf20ao"
      },
      "source": [
        "<font size='4' color='red'>**Task 2.2: Implement a function to test a CNN (6 points).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NuN23oh6xXs"
      },
      "outputs": [],
      "source": [
        "# Function to test an already trained model\n",
        "def test_model(model, data_loader):\n",
        "    \"\"\"\n",
        "    Compute accuracy of the model.\n",
        "\n",
        "    Inputs:\n",
        "      - model: A CNN implemented in PyTorch\n",
        "      - data_loader: A data loader that will provide batched images and labels\n",
        "    \"\"\"\n",
        "\n",
        "    # set the model in evaluation mode so the batch norm layers will behave correctly\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "    with torch.no_grad():\n",
        "        for batch_data in data_loader:\n",
        "            images, labels = batch_data\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "            predicted = None\n",
        "            ############################################################################\n",
        "            # TODO: Compute the predicted labels of the batched input images and store #\n",
        "            # them in the predicted varaible.                                          #\n",
        "            ############################################################################\n",
        "            raise NotImplementedError\n",
        "            ############################################################################\n",
        "            #                             END OF YOUR CODE                             #\n",
        "            ############################################################################\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = 100 * correct // total\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3R-tg8Vd26XZ"
      },
      "source": [
        "<font size='4' color='red'>**Task 2.3: Implement a function to train and validate a CNN (11 points).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3lzA5IOsvtO"
      },
      "outputs": [],
      "source": [
        "def train_val_model(model, train_data_loader, val_data_loader, loss_fn, optimizer, lr_scheduler, num_epochs, print_freq=50):\n",
        "    \"\"\"\n",
        "    Training and validating a CNN model using PyTorch.\n",
        "\n",
        "    Inputs:\n",
        "      - model: A CNN implemented in PyTorch\n",
        "      - data_loader: A data loader that will provide batched images and labels\n",
        "      - loss_fn: A loss function (e.g., cross entropy loss)\n",
        "      - lr_scheduler: Learning rate scheduler\n",
        "      - num_epochs: Number of epochs in total\n",
        "      - print_freq: Frequency to print training statistics\n",
        "\n",
        "    Output:\n",
        "      - model: Trained CNN model\n",
        "    \"\"\"\n",
        "\n",
        "    for epoch_i in range(num_epochs):\n",
        "        # set the model in the train mode so the batch norm layers will behave correctly\n",
        "        model.train()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_total = 0.0\n",
        "        running_correct = 0.0\n",
        "        for i, batch_data in enumerate(train_data_loader):\n",
        "            # Every data instance is an image + label pair\n",
        "            images, labels = batch_data\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "            predicted = None\n",
        "            ############################################################################\n",
        "            # TODO: Finish loss computation, gradient backpropagation, weight update,  #\n",
        "            # and computing the predicted labels of the input images and store them in #\n",
        "            # the predicted varaible, which will be used to monitor the training       #\n",
        "            # accuracy.                                                                #\n",
        "            #                                                                          #\n",
        "            # Note: The learning rate is updated after each **epoch**.                 #\n",
        "            ############################################################################\n",
        "            raise NotImplementedError\n",
        "            ############################################################################\n",
        "            #                             END OF YOUR CODE                             #\n",
        "            ############################################################################\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            running_total += labels.size(0)\n",
        "            running_correct += (predicted == labels).sum().item()\n",
        "            if i % print_freq == 0:    # print every certain number of mini-batches\n",
        "                running_loss = running_loss / print_freq\n",
        "                running_acc = running_correct / running_total * 100\n",
        "                last_lr = lr_scheduler.get_last_lr()[0]\n",
        "                print(f'[{epoch_i + 1}/{num_epochs}, {i + 1:5d}/{len(train_data_loader)}] loss: {running_loss:.3f} acc: {running_acc:.3f} lr: {last_lr:.5f}')\n",
        "                running_loss = 0.0\n",
        "                running_total = 0.0\n",
        "                running_correct = 0.0\n",
        "\n",
        "        # adjust the learning rate\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        val_acc = test_model(model, val_data_loader)\n",
        "        print(f'[{epoch_i + 1}/{num_epochs}] val acc: {val_acc:.3f}')\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S17pDVCR3k-Z"
      },
      "source": [
        "<font size='4' color='red'>**Task 2.4: Implement a function to set up the loss function, optimizer, and learning rate scheduler (8 points).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Z62RTUR7GFx"
      },
      "outputs": [],
      "source": [
        "def set_up_loss_optimizer_lr_scheduler(model, learning_rate, momentum, lr_step_size, lr_gamma):\n",
        "    \"\"\"\n",
        "    In this programming assignment, we will adopt the most common choice for the optimizer:\n",
        "    SGD + momentum and learning rate scheduler: StepLR. Please refer to https://pytorch.org/docs/stable/optim.html#algorithms\n",
        "    and https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR for more details.\n",
        "    \"\"\"\n",
        "    loss_fn = None\n",
        "    optimizer = None\n",
        "    lr_scheduler = None\n",
        "\n",
        "    ############################################################################\n",
        "    # TODO: Define the loss function, optimizer (SGD + momentum), and          #\n",
        "    # learning rate scheduler (StepLR).                                        #\n",
        "    #                                                                          #\n",
        "    # Note: We expect you to set up the learning rate in an epoch-based way.   #\n",
        "    # We will run the learning rate scheduler after each epoch.                #\n",
        "    ############################################################################\n",
        "    raise NotImplementedError\n",
        "    ############################################################################\n",
        "    #                             END OF YOUR CODE                             #\n",
        "    ############################################################################\n",
        "\n",
        "    return loss_fn, optimizer, lr_scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SILUG9AvTl7e"
      },
      "outputs": [],
      "source": [
        "# no need to implement anything here\n",
        "def set_up_cifar10_data_loader(images, labels, batch_size, shuffle=True):\n",
        "    dataset = torch.utils.data.TensorDataset(torch.Tensor(images), torch.Tensor(labels))\n",
        "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=2)\n",
        "    return data_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWq-UEpN4irT"
      },
      "source": [
        "<font size='4' color='red'>**Task 2.5: Train a good custom CNN (10 points).**\n",
        "\n",
        "<font size='4'>By tweaking different hyper parameters, such as number of convolution layers, number of filters (channels), learning rate, batch size, etc, you should achieve greater than 60% accuracy on the testing set **with 3 epochs using the SGD + momentum optimizer**.\n",
        "    \n",
        "<font size='4' color='red'>**Note: The total number of parameters of your custom CNN should be smaller than 180K.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3aYdXSHezba"
      },
      "outputs": [],
      "source": [
        "# In practice, this is a hyperparameter to tune.\n",
        "# But here we use a fixed number to make the comparisons fair.\n",
        "num_epochs = 3\n",
        "\n",
        "model = None\n",
        "loss_fn = None\n",
        "optimizer = None\n",
        "lr_scheduler = None\n",
        "############################################################################\n",
        "# TODO: Set up and tune the hyper parameters.                              #\n",
        "############################################################################\n",
        "batch_size = 1\n",
        "learning_rate = 1\n",
        "momentum = 1\n",
        "lr_gamma = 1\n",
        "\n",
        "model = None\n",
        "loss_fn = None\n",
        "optimizer = None\n",
        "lr_scheduler = None\n",
        "############################################################################\n",
        "#                             END OF YOUR CODE                             #\n",
        "############################################################################\n",
        "\n",
        "model = model.cuda()\n",
        "num_params = sum(p.numel() for p in model.parameters())\n",
        "print('Number of parameters: {:.3f}K'.format(num_params / 1000))\n",
        "\n",
        "# set up the data loaders\n",
        "# note the usage of the batch_size hyperparameter here\n",
        "train_loader = set_up_cifar10_data_loader(data['X_train'], data['y_train'], batch_size, shuffle=True)\n",
        "print(\"There are {} batches in the training set.\".format(len(train_loader)))\n",
        "\n",
        "val_loader = set_up_cifar10_data_loader(data['X_val'], data['y_val'], batch_size, shuffle=False)\n",
        "print(\"There are {} batches in the validation set.\".format(len(val_loader)))\n",
        "\n",
        "test_loader = set_up_cifar10_data_loader(data['X_test'], data['y_test'], batch_size, shuffle=False)\n",
        "print(\"There are {} batches in the testing set.\".format(len(test_loader)))\n",
        "\n",
        "model = train_val_model(model, train_loader, val_loader, loss_fn, optimizer, lr_scheduler, num_epochs)\n",
        "test_acc = test_model(model, test_loader)\n",
        "print(f\"testing accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvq44ocMCa8Y"
      },
      "source": [
        "<font size='4' color='red'>**Task 2.6: Implement a ResNet-like CNN (11 points).**\n",
        "\n",
        "<font size='4'> In practice, we can borrow the existing model design for our task. ResNet (residual network) is a classical design and being used in many places. Let's experiment with it here. Since we are dealing with small images (32x32), regular ResNets are too deep with too much downsampling. We need to chop off a few blocks to reduce the depth and downsampling factor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wf64PXQ9B5Vt"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "from typing import Any, Callable, List, Optional, Type, Union\n",
        "from torchvision.models.resnet import conv1x1, conv3x3, BasicBlock, Bottleneck, ResNet\n",
        "\n",
        "class MyResNet(ResNet):\n",
        "    def __init__(\n",
        "        self,\n",
        "        block: Type[Union[BasicBlock, Bottleneck]],\n",
        "        layers: List[int],\n",
        "        num_classes: int = 1000,\n",
        "        zero_init_residual: bool = False,\n",
        "        groups: int = 1,\n",
        "        width_per_group: int = 64,\n",
        "        replace_stride_with_dilation: Optional[List[bool]] = None,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Here we will design a model architecture MyResNet, inherited from the ResNet model.\n",
        "        First check here https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py about the\n",
        "        implementation of ResNet in PyTorch.\n",
        "        What you need to do in this part is the remove the layer3 and layer4 and also modify the final\n",
        "        fully-connected layer accordingly.\n",
        "        \"\"\"\n",
        "        super().__init__(\n",
        "            block, layers, num_classes, zero_init_residual, groups,\n",
        "            width_per_group, replace_stride_with_dilation, norm_layer\n",
        "        )\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Remove the layer3 and layer4 block in the original implementation  #\n",
        "        # of ResNet and modify the fully-connected layer (classifier) accordingly. #\n",
        "        ############################################################################\n",
        "        raise NotImplementedError\n",
        "        ############################################################################\n",
        "        #                             END OF YOUR CODE                             #\n",
        "        ############################################################################\n",
        "\n",
        "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
        "        logits = None\n",
        "        feat_before_gap = None\n",
        "        ############################################################################\n",
        "        # TODO: Implement the forward pass for the ResNet-like model,              #\n",
        "        # computing the class scores for x and storing them in the logits          #\n",
        "        # variable. Also, store the feature map right before the global average    #\n",
        "        # pooling (GAP) layer in the feat_before_gap variable for debugging        #\n",
        "        # purpose only.                                                            #\n",
        "        ############################################################################\n",
        "        raise NotImplementedError\n",
        "        ############################################################################\n",
        "        #                             END OF YOUR CODE                             #\n",
        "        ############################################################################\n",
        "\n",
        "        return logits, feat_before_gap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HHhTJzi54Yz"
      },
      "outputs": [],
      "source": [
        "# Let's run a sanity check of your model\n",
        "model = MyResNet(BasicBlock, [2, 2, 2, 2], num_classes=10)\n",
        "\n",
        "x = torch.rand((4, 3, 32, 32))\n",
        "logits, feat_before_gap = model(x)\n",
        "assert logits.shape == torch.Size([4, 10]), \"Incorrect shape for the logits\"\n",
        "assert feat_before_gap.shape[2:] == torch.Size([4, 4]), \"Incorrect shape for the feature map before the GAP layer\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyYdJDdy5yAo"
      },
      "source": [
        "<font size='4' color='red'>**Task 2.7: Train a good custom ResNet-like model (6 points).**\n",
        "\n",
        "<font size='4'>Here we use the same batch size used in the tweaking of your custom CNN. We will also simply use (part of) the ResNet18 model. You only need to tune learning rate, momentum, learning rate decay rate here. You should achieve greater than 70% accuracy on the testing set **with 3 epochs using the SGD + momentum optimizer**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kzrnj9N7DD9N"
      },
      "outputs": [],
      "source": [
        "# In practice, this is a hyperparameter to tune.\n",
        "# But here we use a fixed number to make the comparisons fair.\n",
        "num_epochs = 3\n",
        "\n",
        "model = MyResNet(BasicBlock, [2, 2, 2, 2], num_classes=10)\n",
        "############################################################################\n",
        "# TODO: Set up and tune the hyper parameters.                              #\n",
        "############################################################################\n",
        "learning_rate = 1\n",
        "momentum = 1\n",
        "lr_gamma = 1\n",
        "\n",
        "loss_fn = None\n",
        "optimizer = None\n",
        "lr_scheduler = None\n",
        "############################################################################\n",
        "#                             END OF YOUR CODE                             #\n",
        "############################################################################\n",
        "\n",
        "# set up the data loaders\n",
        "# note the usage of the batch_size hyperparameter here\n",
        "train_loader = set_up_cifar10_data_loader(data['X_train'], data['y_train'], batch_size, shuffle=True)\n",
        "print(\"There are {} batches in the training set.\".format(len(train_loader)))\n",
        "\n",
        "val_loader = set_up_cifar10_data_loader(data['X_val'], data['y_val'], batch_size, shuffle=False)\n",
        "print(\"There are {} batches in the validation set.\".format(len(val_loader)))\n",
        "\n",
        "test_loader = set_up_cifar10_data_loader(data['X_test'], data['y_test'], batch_size, shuffle=False)\n",
        "print(\"There are {} batches in the testing set.\".format(len(test_loader)))\n",
        "\n",
        "model = MyResNet(BasicBlock, [2, 2, 2, 2], num_classes=10)\n",
        "num_params = sum(p.numel() for p in model.parameters())\n",
        "print('Number of parameters: {:.3f}K'.format(num_params / 1000))\n",
        "\n",
        "model = model.cuda()\n",
        "model = train_val_model(model, train_loader, val_loader, loss_fn, optimizer, lr_scheduler, num_epochs)\n",
        "test_acc = test_model(model, test_loader)\n",
        "print(f\"testing accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9yxslIX6e7l"
      },
      "source": [
        "<font size='4' color='red'>**Task 2.8: Train a the same ResNet-like model but with ImageNet pre-trained weights (transfer learning, 8 points).**\n",
        "\n",
        "<font size='4'>Here we use the same batch size used in the tweaking of your custom CNN. We will also simply use the same ResNet18-like model. You only need to tune learning rate, momentum, learning rate decay rate here. You should achieve greater than 80% accuracy on the testing set **with 3 epochs using the SGD + momentum optimizer**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJtsipToEiJq"
      },
      "outputs": [],
      "source": [
        "# Let's experiment with transfer learning by borrowing the weights of a ResNet model pre-trained on ImageNet.\n",
        "import torchvision\n",
        "imagenet_resnet18 = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights)\n",
        "model = MyResNet(BasicBlock, [2, 2, 2, 2], num_classes=10)\n",
        "num_params = sum(p.numel() for p in model.parameters())\n",
        "print('Number of parameters: {:.3f}K'.format(num_params / 1000))\n",
        "\n",
        "############################################################################\n",
        "# TODO: Copy the appropriate weights from imagenet_resnet18 to our custom  #\n",
        "# model, which shares part of the network architecture.                    #\n",
        "############################################################################\n",
        "raise NotImplementedError\n",
        "############################################################################\n",
        "#                             END OF YOUR CODE                             #\n",
        "############################################################################\n",
        "\n",
        "############################################################################\n",
        "# TODO: Set up and tune the hyper parameters.                              #\n",
        "############################################################################\n",
        "learning_rate = 1\n",
        "momentum = 1\n",
        "lr_gamma = 1\n",
        "\n",
        "loss_fn = None\n",
        "optimizer = None\n",
        "lr_scheduler = None\n",
        "############################################################################\n",
        "#                             END OF YOUR CODE                             #\n",
        "############################################################################\n",
        "\n",
        "# set up the data loaders\n",
        "# note the usage of the batch_size hyperparameter here\n",
        "train_loader = set_up_cifar10_data_loader(data['X_train'], data['y_train'], batch_size, shuffle=True)\n",
        "print(\"There are {} batches in the training set.\".format(len(train_loader)))\n",
        "\n",
        "val_loader = set_up_cifar10_data_loader(data['X_val'], data['y_val'], batch_size, shuffle=False)\n",
        "print(\"There are {} batches in the validation set.\".format(len(val_loader)))\n",
        "\n",
        "test_loader = set_up_cifar10_data_loader(data['X_test'], data['y_test'], batch_size, shuffle=False)\n",
        "print(\"There are {} batches in the testing set.\".format(len(test_loader)))\n",
        "\n",
        "model = model.cuda()\n",
        "model = train_val_model(model, train_loader, val_loader, loss_fn, optimizer, lr_scheduler, num_epochs)\n",
        "test_acc = test_model(model, test_loader)\n",
        "print(f\"testing accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KluK8QC3DiGg"
      },
      "source": [
        "<font size='4' color='red'>**Task 2.9: Briefly explain below why you got increasinly better accuracy from Task 2.5 to Task 2.8 (3 points)** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tK3NGPoxDxeS"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_NOHlEorJ0J"
      },
      "source": [
        "<font size='4' color='red'> **Part 3: Extra credits (10 points).**\n",
        "\n",
        "<font size='4'> Let's do something fun here. You can do whatever you can use. Earn the full credits by achieving at least 91% accuracy on the testing set with the following restrictions:\n",
        "- Train the model for no more than 5 epochs.\n",
        "- Use a model whose number of parameters is smaller than 2M.\n",
        "- Use a convolutional neural network\n",
        "\n",
        "<font size='4' color='red'> **Note**: If you have to override any function you implemented earlier, write new code below. Do not change the function definition in previous sections so that we can grade your implementation appopriately.\n",
        "\n",
        "<font size='4' color='red'> **No partial credits will be given to this part. In other words, you won't get any credits if your final testing accuracy is lower than 91%.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "argoverse",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
